{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0239fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from optuna_dashboard import run_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = Path(\"/Users/maryamhomayoon/PycharmProjects/optuna/optuna-examples/db.sqlite3\")\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "STORAGE = f\"sqlite:///{DB_PATH.as_posix()}\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE.type == \"mps\":\n",
    "    torch.mps.manual_seed(SEED)\n",
    "else:\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "# N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "# N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple model with only linear layer\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and #dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    layers = []\n",
    "    in_out_features = [] \n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_out_features.append((in_features, out_features))\n",
    "        # p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        # layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    in_out_features.append((in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers) , in_out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with conv and pooling and linear layer\n",
    "def define_model(trial):\n",
    "    layers = []\n",
    "    # FashionMNIST is 28x28 grayscale images\n",
    "    in_channels = 1\n",
    "    in_height = 28\n",
    "    in_width = 28\n",
    "\n",
    "    current_features = None\n",
    "    spatial_mode = True # a flag to control what architecture are allowed and that spatial sturctures of the connected layers makes sense\n",
    "    used_global_pool = False # we can classify with conv -> global pooling -> classifier(log softmax)\n",
    "\n",
    "    layer_descriptions = []\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # First layer should be conv or if it's not conv then we need to flatten the input\n",
    "        # last layer should either be linear or we have to apply a conv with 10 output channels and then we have to apply global pooling and then classifier\n",
    "        # 10 channel conv beacause it's FashionMNIST dataset\n",
    "        # if the last global pool is not with 10 out channel then we linearly have it to 10 classes output and then go for classifier\n",
    "\n",
    "        if layer_idx == 0:\n",
    "            layer_type = \"conv\"\n",
    "\n",
    "        elif spatial_mode:\n",
    "            layer_type = trial.suggest_categorical(\n",
    "                f\"layer_type_{layer_idx}\",\n",
    "                [\"conv\", \"pool\", \"global_pool\", \"linear\"]\n",
    "            )\n",
    "        else:\n",
    "            # Once spatial structure is gone, only Linear is allowed\n",
    "            layer_type = \"linear\"\n",
    "\n",
    "\n",
    "        if layer_type == \"conv\":\n",
    "            out_channels = trial.suggest_categorical(\n",
    "                f\"conv_out_channels_{layer_idx}\", [16, 32, 64, 128, 256, 512]\n",
    "            )\n",
    "\n",
    "            kernel_size = trial.suggest_int(\n",
    "                f\"conv_kernel_{layer_idx}\", 1, 7, step=2\n",
    "            )\n",
    "\n",
    "            stride = trial.suggest_categorical(\n",
    "                f\"conv_stride_{layer_idx}\", [1, 2]\n",
    "            )\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=\"same\",\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            # SAME padding output size\n",
    "            in_height = (in_height + stride - 1) // stride\n",
    "            in_width = (in_width + stride - 1) // stride\n",
    "            in_channels = out_channels\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"conv2d\",\n",
    "                \"out_channels\": out_channels,\n",
    "                \"kernel_size\": kernel_size,\n",
    "                \"stride\": stride,\n",
    "                \"input_shape\": (in_channels, in_height, in_width),\n",
    "            })\n",
    "\n",
    "\n",
    "        elif layer_type == \"pool\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            in_height //= 2\n",
    "            in_width //= 2\n",
    "            # channels unchanged\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"maxpool2d\",\n",
    "                \"kernel_size\": 2,\n",
    "                \"stride\": 2,\n",
    "                \"input_shape\": (in_channels, in_height, in_width),\n",
    "            })\n",
    "\n",
    "   \n",
    "        elif layer_type == \"global_pool\":\n",
    "            layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "\n",
    "            current_features = in_channels\n",
    "            in_channels = None\n",
    "            in_height = None\n",
    "            in_width = None\n",
    "\n",
    "            spatial_mode = False\n",
    "            used_global_pool = True\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"global_avg_pool\",\n",
    "                \"features\": current_features,\n",
    "            })\n",
    "\n",
    "        else:  # linear\n",
    "            if spatial_mode:\n",
    "                layers.append(nn.Flatten())\n",
    "                current_features = in_channels * in_height * in_width\n",
    "                spatial_mode = False\n",
    "\n",
    "            out_features = trial.suggest_int(\n",
    "                f\"linear_out_{layer_idx}\", 16, 128\n",
    "            )\n",
    "\n",
    "            layers.append(nn.Linear(current_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": out_features,\n",
    "            })\n",
    "\n",
    "            current_features = out_features\n",
    "\n",
    "    if used_global_pool:\n",
    "        # If global pooling was used, we may already have features\n",
    "        if current_features != CLASSES:\n",
    "            layers.append(nn.Linear(current_features, CLASSES))\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": CLASSES,\n",
    "            })\n",
    "    else:\n",
    "        # No global pool â†’ must flatten and use Linear\n",
    "        if spatial_mode:\n",
    "            layers.append(nn.Flatten())\n",
    "            current_features = in_channels * in_height * in_width\n",
    "\n",
    "        layers.append(nn.Linear(current_features, CLASSES))\n",
    "        layer_descriptions.append({\n",
    "            \"type\": \"linear\",\n",
    "            \"in_features\": current_features,\n",
    "            \"out_features\": CLASSES,\n",
    "        })\n",
    "\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers), layer_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with conv and linear while taking care of padding and while trying different strides\n",
    "def define_model(trial):\n",
    "    layers = []\n",
    "    # FashionMNIST is 28x28 grayscale images\n",
    "    in_channels = 1\n",
    "    in_height = 28\n",
    "    in_width = 28\n",
    "\n",
    "    current_features = None\n",
    "    spatial_mode = True     # a flag to control what architecture are allowed and that spatial sturctures of the connected layers makes sense\n",
    "    used_global_pool = False    # we can classify with conv -> global pooling -> classifier(log softmax)\n",
    "\n",
    "    layer_descriptions = []\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # First layer should be conv or if it's not conv then we need to flatten the input\n",
    "        # last layer should either be linear or we have to apply a conv with 10 output channels and then we have to apply global pooling and then classifier\n",
    "        # 10 channel conv beacause it's FashionMNIST dataset\n",
    "        # if the last global pool is not with 10 out channel then we linearly have it to 10 classes output and then go for classifier\n",
    "        if layer_idx == 0:\n",
    "            layer_type = \"conv\"\n",
    "        elif spatial_mode:\n",
    "            layer_type = trial.suggest_categorical(\n",
    "                f\"layer_type_{layer_idx}\",\n",
    "                [\"conv\", \"pool\", \"global_pool\", \"linear\"]\n",
    "            )\n",
    "        else:\n",
    "            # Once spatial structure is gone, only Linear is allowed\n",
    "            layer_type = \"linear\"\n",
    "\n",
    "        if layer_type == \"conv\":\n",
    "            out_channels = trial.suggest_categorical(\n",
    "                f\"conv_out_channels_{layer_idx}\", [16, 32, 64, 128, 256, 512]\n",
    "            )\n",
    "            kernel_size = trial.suggest_int(\n",
    "                f\"conv_kernel_{layer_idx}\", 1, 7, step=2  # odd only\n",
    "            )\n",
    "            stride = trial.suggest_categorical(\n",
    "                f\"conv_stride_{layer_idx}\", [1, 2]\n",
    "            )\n",
    "\n",
    "            # Save input shape BEFORE the layer (for latency)\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            padding = kernel_size // 2  # works with odd kernels for stride 1 and 2\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            # Output size tracking (matches your \"ceil\" style)\n",
    "            out_h = (h_in + stride - 1) // stride\n",
    "            out_w = (w_in + stride - 1) // stride\n",
    "\n",
    "            in_channels = out_channels\n",
    "            in_height = out_h\n",
    "            in_width = out_w\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"conv2d\",\n",
    "                \"out_channels\": out_channels,\n",
    "                \"kernel_size\": kernel_size,\n",
    "                \"stride\": stride,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            in_height = h_in // 2\n",
    "            in_width = w_in // 2\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"maxpool2d\",\n",
    "                \"kernel_size\": 2,\n",
    "                \"stride\": 2,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"global_pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "            layers.append(nn.Flatten())\n",
    "\n",
    "            current_features = c_in\n",
    "\n",
    "            spatial_mode = False\n",
    "            used_global_pool = True\n",
    "\n",
    "            # After flatten, no more spatial dims\n",
    "            in_channels = None\n",
    "            in_height = None\n",
    "            in_width = None\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"global_avg_pool\",\n",
    "                \"features\": current_features,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        else:  # linear\n",
    "            if spatial_mode:\n",
    "                layers.append(nn.Flatten())\n",
    "                current_features = in_channels * in_height * in_width\n",
    "                spatial_mode = False\n",
    "\n",
    "                in_channels = None\n",
    "                in_height = None\n",
    "                in_width = None\n",
    "\n",
    "            out_features = trial.suggest_int(\n",
    "                f\"linear_out_{layer_idx}\", 16, 128\n",
    "            )\n",
    "\n",
    "            layers.append(nn.Linear(current_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": out_features,\n",
    "            })\n",
    "\n",
    "            current_features = out_features\n",
    "\n",
    "    # Final classifier head\n",
    "    if used_global_pool:\n",
    "        if current_features != CLASSES:\n",
    "            layers.append(nn.Linear(current_features, CLASSES))\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": CLASSES,\n",
    "            })\n",
    "    else:\n",
    "        if spatial_mode:\n",
    "            layers.append(nn.Flatten())\n",
    "            current_features = in_channels * in_height * in_width\n",
    "\n",
    "        layers.append(nn.Linear(current_features, CLASSES))\n",
    "        layer_descriptions.append({\n",
    "            \"type\": \"linear\",\n",
    "            \"in_features\": current_features,\n",
    "            \"out_features\": CLASSES,\n",
    "        })\n",
    "\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers), layer_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_linear_latency(in_features, out_features, num_cores=1):\n",
    "    forward = in_features * out_features + out_features # + bias\n",
    "    backward = 2 * forward # grad w.r.t input, grad w.r.t to weight, grad w.r.t bias so we roughly say cost of backward is twice as much of forward\n",
    "    optimizer = 3 * forward # adam have to do some arithmetic calculations to update each weight so we assume that the cost of those are 3\n",
    "    latency = (forward + backward + optimizer) / num_cores \n",
    "    \n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_conv_latency(input_channels, output_channels, input_height, input_width, kernel_size, stride=1, num_cores=1):\n",
    "    # to formulate the cost of conv layer we check how many output positions we have and how many arithmatic calculations we need to do\n",
    "\n",
    "    # Output spatial size\n",
    "    output_height = (input_height + stride - 1) // stride\n",
    "    output_width  = (input_width  + stride - 1) // stride\n",
    "\n",
    "    # Cost of computing ONE output value\n",
    "    kernel_area = kernel_size * kernel_size\n",
    "    operations_per_output_value = input_channels * kernel_area + 1 # + bias\n",
    "\n",
    "    # Number of output values\n",
    "    number_of_output_values = output_channels * output_height * output_width\n",
    "\n",
    "\n",
    "    forward = operations_per_output_value * number_of_output_values\n",
    "    backward = 2 * forward\n",
    "    optimizer = 3 * forward\n",
    "    latency = (forward + backward + optimizer) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c09564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_maxpool_latency(channels, input_height, input_width, kernel_size=2, stride=2, num_cores=1):\n",
    "    \"\"\"\n",
    "    Estimate arithmetic cost of MaxPool2d for ONE input sample.\n",
    "    \"\"\"\n",
    "\n",
    "    # Output spatial size\n",
    "    output_height = input_height // stride\n",
    "    output_width = input_width // stride\n",
    "\n",
    "    kernel_area = kernel_size * kernel_size\n",
    "\n",
    "    # Comparisons per output value\n",
    "    operations_per_output_value = kernel_area - 1\n",
    "\n",
    "    number_of_output_values = channels * output_height * output_width\n",
    "\n",
    "    forward_cost = operations_per_output_value * number_of_output_values\n",
    "    backward_cost = forward_cost    # Backward (no optimizer)\n",
    "    latency = (forward_cost + backward_cost) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_global_avg_pool_latency(channels, input_height, input_width, num_cores=1):\n",
    "    \"\"\"\n",
    "    Estimate arithmetic cost of Global Average Pooling for ONE input sample.\n",
    "    \"\"\"\n",
    "\n",
    "    spatial_area = input_height * input_width\n",
    "    \n",
    "    forward_cost = channels * spatial_area  # Forward: sum + divide\n",
    "    backward_cost = forward_cost    # Backward: distribute gradient\n",
    "    latency = (forward_cost + backward_cost) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple linear model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    latency = 0.0\n",
    "\n",
    "    for i, (in_f, out_f) in enumerate(out):\n",
    "        latency += estimate_linear_latency(in_f, out_f,num_cores=1, batch=BATCHSIZE)\n",
    "    trial.set_user_attr(\"latency_ms_est\", latency)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)    # since we only have linear layers we need to flatten the input first\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95487b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for conv model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    trial.set_user_attr(\"arch\", arch)         # best one to store\n",
    "    trial.set_user_attr(\"model_str\", str(model))  # optional, human-readable\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    latency = 0.0\n",
    "\n",
    "    for layer in out:\n",
    "\n",
    "        if layer[\"type\"] == \"conv2d\":\n",
    "            c_in, h_in, w_in = layer[\"input_shape\"]\n",
    "            latency += estimate_conv_latency(input_channels=c_in, output_channels=layer[\"out_channels\"], input_height=h_in, input_width=w_in, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"maxpool2d\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            latency += estimate_maxpool_latency(channels=c, input_height=h, input_width=w, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"global_avg_pool\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            latency += estimate_global_avg_pool_latency(channels=c, input_height=h, input_width=w)\n",
    "\n",
    "        elif layer[\"type\"] == \"linear\":\n",
    "            latency += estimate_linear_latency(layer[\"in_features\"], layer[\"out_features\"])\n",
    "\n",
    "    trial.set_user_attr(\"latency_ms_est\", latency)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78634e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    directions=[\"maximize\",\"minimize\"],\n",
    "    study_name=\"first try for the conv model\",\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "import json\n",
    "\n",
    "pareto = []\n",
    "for t in study.best_trials:\n",
    "    pareto.append({\n",
    "        \"trial_number\": t.number,\n",
    "        \"values\": t.values,     # [accuracy, latency]\n",
    "        \"params\": t.params,\n",
    "        \"arch\": t.user_attrs.get(\"arch\"),\n",
    "    })\n",
    "\n",
    "with open(\"pareto_trials.json\", \"w\") as f:\n",
    "    json.dump(pareto, f, indent=2)\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# best_trials = study.best_trials\n",
    "# print(f\"\\nNumber of Pareto-optimal trials: {len(best_trials)}\")\n",
    "\n",
    "# for t in best_trials:\n",
    "#     print(f\"  Values: accuracy={t.values[0]:.4f}, latency={t.values[1]:.4f}\")\n",
    "#     print(\"  Params:\")\n",
    "#     for k, v in t.params.items():\n",
    "#         print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the Optuna Dashboard server on localhost:8080\n",
    "run_server(STORAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
