{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0239fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from optuna_dashboard import run_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b989047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = Path(\"/Users/maryamhomayoon/PycharmProjects/optuna/optuna-examples/db.sqlite3\")\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "STORAGE = f\"sqlite:///{DB_PATH.as_posix()}\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE.type == \"mps\":\n",
    "    torch.mps.manual_seed(SEED)\n",
    "else:\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "# N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "# N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple model with only linear layer\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and #dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    layers = []\n",
    "    in_out_features = [] \n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_out_features.append((in_features, out_features))\n",
    "        # p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        # layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    in_out_features.append((in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers) , in_out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with conv and pooling and linear layer\n",
    "def define_model(trial):\n",
    "    layers = []\n",
    "    # FashionMNIST is 28x28 grayscale images\n",
    "    in_channels = 1\n",
    "    in_height = 28\n",
    "    in_width = 28\n",
    "\n",
    "    current_features = None\n",
    "    spatial_mode = True # a flag to control what architecture are allowed and that spatial sturctures of the connected layers makes sense\n",
    "    used_global_pool = False # we can classify with conv -> global pooling -> classifier(log softmax)\n",
    "\n",
    "    layer_descriptions = []\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # First layer should be conv or if it's not conv then we need to flatten the input\n",
    "        # last layer should either be linear or we have to apply a conv with 10 output channels and then we have to apply global pooling and then classifier\n",
    "        # 10 channel conv beacause it's FashionMNIST dataset\n",
    "        # if the last global pool is not with 10 out channel then we linearly have it to 10 classes output and then go for classifier\n",
    "\n",
    "        if layer_idx == 0:\n",
    "            layer_type = \"conv\"\n",
    "\n",
    "        elif spatial_mode:\n",
    "            layer_type = trial.suggest_categorical(\n",
    "                f\"layer_type_{layer_idx}\",\n",
    "                [\"conv\", \"pool\", \"global_pool\", \"linear\"]\n",
    "            )\n",
    "        else:\n",
    "            # Once spatial structure is gone, only Linear is allowed\n",
    "            layer_type = \"linear\"\n",
    "\n",
    "\n",
    "        if layer_type == \"conv\":\n",
    "            out_channels = trial.suggest_categorical(\n",
    "                f\"conv_out_channels_{layer_idx}\", [16, 32, 64, 128, 256, 512]\n",
    "            )\n",
    "\n",
    "            kernel_size = trial.suggest_int(\n",
    "                f\"conv_kernel_{layer_idx}\", 1, 7, step=2\n",
    "            )\n",
    "\n",
    "            stride = trial.suggest_categorical(\n",
    "                f\"conv_stride_{layer_idx}\", [1, 2]\n",
    "            )\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=\"same\",\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            # SAME padding output size\n",
    "            in_height = (in_height + stride - 1) // stride\n",
    "            in_width = (in_width + stride - 1) // stride\n",
    "            in_channels = out_channels\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"conv2d\",\n",
    "                \"out_channels\": out_channels,\n",
    "                \"kernel_size\": kernel_size,\n",
    "                \"stride\": stride,\n",
    "                \"input_shape\": (in_channels, in_height, in_width),\n",
    "            })\n",
    "\n",
    "\n",
    "        elif layer_type == \"pool\":\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            in_height //= 2\n",
    "            in_width //= 2\n",
    "            # channels unchanged\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"maxpool2d\",\n",
    "                \"kernel_size\": 2,\n",
    "                \"stride\": 2,\n",
    "                \"input_shape\": (in_channels, in_height, in_width),\n",
    "            })\n",
    "\n",
    "   \n",
    "        elif layer_type == \"global_pool\":\n",
    "            layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "\n",
    "            current_features = in_channels\n",
    "            in_channels = None\n",
    "            in_height = None\n",
    "            in_width = None\n",
    "\n",
    "            spatial_mode = False\n",
    "            used_global_pool = True\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"global_avg_pool\",\n",
    "                \"features\": current_features,\n",
    "            })\n",
    "\n",
    "        else:  # linear\n",
    "            if spatial_mode:\n",
    "                layers.append(nn.Flatten())\n",
    "                current_features = in_channels * in_height * in_width\n",
    "                spatial_mode = False\n",
    "\n",
    "            out_features = trial.suggest_int(\n",
    "                f\"linear_out_{layer_idx}\", 16, 128\n",
    "            )\n",
    "\n",
    "            layers.append(nn.Linear(current_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": out_features,\n",
    "            })\n",
    "\n",
    "            current_features = out_features\n",
    "\n",
    "    if used_global_pool:\n",
    "        # If global pooling was used, we may already have features\n",
    "        if current_features != CLASSES:\n",
    "            layers.append(nn.Linear(current_features, CLASSES))\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": CLASSES,\n",
    "            })\n",
    "    else:\n",
    "        # No global pool â†’ must flatten and use Linear\n",
    "        if spatial_mode:\n",
    "            layers.append(nn.Flatten())\n",
    "            current_features = in_channels * in_height * in_width\n",
    "\n",
    "        layers.append(nn.Linear(current_features, CLASSES))\n",
    "        layer_descriptions.append({\n",
    "            \"type\": \"linear\",\n",
    "            \"in_features\": current_features,\n",
    "            \"out_features\": CLASSES,\n",
    "        })\n",
    "\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers), layer_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f45f37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    in_height = 28\n",
    "    in_width = 28\n",
    "\n",
    "    current_features = None\n",
    "    spatial_mode = True\n",
    "    used_global_pool = False\n",
    "\n",
    "    layer_descriptions = []\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        if layer_idx == 0:\n",
    "            layer_type = \"conv\"\n",
    "        elif spatial_mode:\n",
    "            layer_type = trial.suggest_categorical(\n",
    "                f\"layer_type_{layer_idx}\",\n",
    "                [\"conv\", \"pool\", \"global_pool\", \"linear\"]\n",
    "            )\n",
    "        else:\n",
    "            layer_type = \"linear\"\n",
    "\n",
    "        if layer_type == \"conv\":\n",
    "            out_channels = trial.suggest_categorical(\n",
    "                f\"conv_out_channels_{layer_idx}\", [16, 32, 64, 128, 256, 512]\n",
    "            )\n",
    "            kernel_size = trial.suggest_int(\n",
    "                f\"conv_kernel_{layer_idx}\", 1, 7, step=2  # odd only\n",
    "            )\n",
    "            stride = trial.suggest_categorical(\n",
    "                f\"conv_stride_{layer_idx}\", [1, 2]\n",
    "            )\n",
    "\n",
    "            # Save input shape BEFORE the layer (for latency)\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            padding = kernel_size // 2  # works with odd kernels for stride 1 and 2\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            # Output size tracking (matches your \"ceil\" style)\n",
    "            out_h = (h_in + stride - 1) // stride\n",
    "            out_w = (w_in + stride - 1) // stride\n",
    "\n",
    "            in_channels = out_channels\n",
    "            in_height = out_h\n",
    "            in_width = out_w\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"conv2d\",\n",
    "                \"out_channels\": out_channels,\n",
    "                \"kernel_size\": kernel_size,\n",
    "                \"stride\": stride,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            in_height = h_in // 2\n",
    "            in_width = w_in // 2\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"maxpool2d\",\n",
    "                \"kernel_size\": 2,\n",
    "                \"stride\": 2,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"global_pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "            layers.append(nn.Flatten())  # IMPORTANT so Linear works\n",
    "\n",
    "            current_features = c_in\n",
    "\n",
    "            spatial_mode = False\n",
    "            used_global_pool = True\n",
    "\n",
    "            # After flatten, no more spatial dims\n",
    "            in_channels = None\n",
    "            in_height = None\n",
    "            in_width = None\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"global_avg_pool\",\n",
    "                \"features\": current_features,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        else:  # linear\n",
    "            if spatial_mode:\n",
    "                layers.append(nn.Flatten())\n",
    "                current_features = in_channels * in_height * in_width\n",
    "                spatial_mode = False\n",
    "\n",
    "                in_channels = None\n",
    "                in_height = None\n",
    "                in_width = None\n",
    "\n",
    "            out_features = trial.suggest_int(\n",
    "                f\"linear_out_{layer_idx}\", 16, 128\n",
    "            )\n",
    "\n",
    "            layers.append(nn.Linear(current_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": out_features,\n",
    "            })\n",
    "\n",
    "            current_features = out_features\n",
    "\n",
    "    # Final classifier head\n",
    "    if used_global_pool:\n",
    "        if current_features != CLASSES:\n",
    "            layers.append(nn.Linear(current_features, CLASSES))\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": CLASSES,\n",
    "            })\n",
    "    else:\n",
    "        if spatial_mode:\n",
    "            layers.append(nn.Flatten())\n",
    "            current_features = in_channels * in_height * in_width\n",
    "\n",
    "        layers.append(nn.Linear(current_features, CLASSES))\n",
    "        layer_descriptions.append({\n",
    "            \"type\": \"linear\",\n",
    "            \"in_features\": current_features,\n",
    "            \"out_features\": CLASSES,\n",
    "        })\n",
    "\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers), layer_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580b1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_linear_latency(in_features, out_features, num_cores=1):\n",
    "    forward = in_features * out_features + out_features # + bias\n",
    "    backward = 2 * forward # grad w.r.t input, grad w.r.t to weight, grad w.r.t bias so we roughly say cost of backward is twice as much of forward\n",
    "    optimizer = 3 * forward # adam have to do some arithmetic calculations to update each weight so we assume that the cost of those are 3\n",
    "    latency = (forward + backward + optimizer) / num_cores \n",
    "    \n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cab6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_conv_latency(input_channels, output_channels, input_height, input_width, kernel_size, stride=1, num_cores=1):\n",
    "    # to formulate the cost of conv layer we check how many output positions we have and how many arithmatic calculations we need to do\n",
    "\n",
    "    # Output spatial size\n",
    "    output_height = (input_height + stride - 1) // stride\n",
    "    output_width  = (input_width  + stride - 1) // stride\n",
    "\n",
    "    # Cost of computing ONE output value\n",
    "    kernel_area = kernel_size * kernel_size\n",
    "    operations_per_output_value = input_channels * kernel_area + 1 # + bias\n",
    "\n",
    "    # Number of output values\n",
    "    number_of_output_values = output_channels * output_height * output_width\n",
    "\n",
    "\n",
    "    forward = operations_per_output_value * number_of_output_values\n",
    "    backward = 2 * forward\n",
    "    optimizer = 3 * forward\n",
    "    latency = (forward + backward + optimizer) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c09564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_maxpool_latency(channels, input_height, input_width, kernel_size=2, stride=2, num_cores=1):\n",
    "    \"\"\"\n",
    "    Estimate arithmetic cost of MaxPool2d for ONE input sample.\n",
    "    \"\"\"\n",
    "\n",
    "    # Output spatial size\n",
    "    output_height = input_height // stride\n",
    "    output_width = input_width // stride\n",
    "\n",
    "    kernel_area = kernel_size * kernel_size\n",
    "\n",
    "    # Comparisons per output value\n",
    "    operations_per_output_value = kernel_area - 1\n",
    "\n",
    "    number_of_output_values = channels * output_height * output_width\n",
    "\n",
    "    forward_cost = operations_per_output_value * number_of_output_values\n",
    "    backward_cost = forward_cost    # Backward (no optimizer)\n",
    "    latency = (forward_cost + backward_cost) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565c22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_global_avg_pool_latency(channels, input_height, input_width, num_cores=1):\n",
    "    \"\"\"\n",
    "    Estimate arithmetic cost of Global Average Pooling for ONE input sample.\n",
    "    \"\"\"\n",
    "\n",
    "    spatial_area = input_height * input_width\n",
    "    \n",
    "    forward_cost = channels * spatial_area  # Forward: sum + divide\n",
    "    backward_cost = forward_cost    # Backward: distribute gradient\n",
    "    latency = (forward_cost + backward_cost) / num_cores\n",
    "\n",
    "    return latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40d273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple linear model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    latency = 0.0\n",
    "\n",
    "    for i, (in_f, out_f) in enumerate(out):\n",
    "        latency += estimate_linear_latency(in_f, out_f,num_cores=1, batch=BATCHSIZE)\n",
    "    trial.set_user_attr(\"latency_ms_est\", latency)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)    # since we only have linear layers we need to flatten the input first\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95487b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for conv model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    latency = 0.0\n",
    "\n",
    "    for layer in out:\n",
    "\n",
    "        if layer[\"type\"] == \"conv2d\":\n",
    "            c_in, h_in, w_in = layer[\"input_shape\"]\n",
    "            latency += estimate_conv_latency(input_channels=c_in, output_channels=layer[\"out_channels\"], input_height=h_in, input_width=w_in, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"maxpool2d\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            latency += estimate_maxpool_latency(channels=c, input_height=h, input_width=w, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"global_avg_pool\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            latency += estimate_global_avg_pool_latency(channels=c, input_height=h, input_width=w)\n",
    "\n",
    "        elif layer[\"type\"] == \"linear\":\n",
    "            latency += estimate_linear_latency(layer[\"in_features\"], layer[\"out_features\"])\n",
    "\n",
    "    trial.set_user_attr(\"latency_ms_est\", latency)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78634e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-07 12:23:38,955] Using an existing study with name 'first try for the conv model' instead of creating a new one.\n",
      "[I 2026-02-07 12:24:02,577] Trial 1 finished with values: [0.902, 5009820.0] and parameters: {'n_layers': 3, 'conv_out_channels_0': 16, 'conv_kernel_0': 7, 'conv_stride_0': 2, 'layer_type_1': 'pool', 'layer_type_2': 'conv', 'conv_out_channels_2': 512, 'conv_kernel_2': 1, 'conv_stride_2': 1}.\n",
      "[I 2026-02-07 12:25:33,685] Trial 2 finished with values: [0.8702, 50061618.0] and parameters: {'n_layers': 8, 'conv_out_channels_0': 128, 'conv_kernel_0': 1, 'conv_stride_0': 1, 'layer_type_1': 'linear', 'linear_out_1': 81, 'linear_out_2': 17, 'linear_out_3': 56, 'linear_out_4': 108, 'linear_out_5': 32, 'linear_out_6': 28, 'linear_out_7': 34}.\n",
      "[I 2026-02-07 12:26:07,838] Trial 3 finished with values: [0.8896, 17191320.0] and parameters: {'n_layers': 8, 'conv_out_channels_0': 32, 'conv_kernel_0': 7, 'conv_stride_0': 2, 'layer_type_1': 'conv', 'conv_out_channels_1': 64, 'conv_kernel_1': 5, 'conv_stride_1': 2, 'layer_type_2': 'pool', 'layer_type_3': 'linear', 'linear_out_3': 55, 'linear_out_4': 18, 'linear_out_5': 52, 'linear_out_6': 24, 'linear_out_7': 117}.\n",
      "[I 2026-02-07 12:26:36,697] Trial 4 finished with values: [0.8963, 2862126.0] and parameters: {'n_layers': 6, 'conv_out_channels_0': 32, 'conv_kernel_0': 7, 'conv_stride_0': 2, 'layer_type_1': 'pool', 'layer_type_2': 'linear', 'linear_out_2': 84, 'linear_out_3': 77, 'linear_out_4': 109, 'linear_out_5': 125}.\n",
      "[I 2026-02-07 12:27:31,028] Trial 5 finished with values: [0.7122, 16150780.0] and parameters: {'n_layers': 9, 'conv_out_channels_0': 128, 'conv_kernel_0': 5, 'conv_stride_0': 1, 'layer_type_1': 'global_pool', 'linear_out_2': 115, 'linear_out_3': 74, 'linear_out_4': 48, 'linear_out_5': 20, 'linear_out_6': 91, 'linear_out_7': 87, 'linear_out_8': 115}.\n",
      "[I 2026-02-07 12:28:41,244] Trial 6 finished with values: [0.906, 49502748.0] and parameters: {'n_layers': 6, 'conv_out_channels_0': 256, 'conv_kernel_0': 7, 'conv_stride_0': 2, 'layer_type_1': 'linear', 'linear_out_1': 114, 'linear_out_2': 45, 'linear_out_3': 74, 'linear_out_4': 97, 'linear_out_5': 52}.\n",
      "[I 2026-02-07 12:29:09,791] Trial 7 finished with values: [0.9049, 6021180.0] and parameters: {'n_layers': 1, 'conv_out_channels_0': 256, 'conv_kernel_0': 3, 'conv_stride_0': 2}.\n",
      "[I 2026-02-07 12:30:10,787] Trial 8 finished with values: [0.9043, 42500334.0] and parameters: {'n_layers': 4, 'conv_out_channels_0': 64, 'conv_kernel_0': 5, 'conv_stride_0': 1, 'layer_type_1': 'linear', 'linear_out_1': 115, 'linear_out_2': 41, 'linear_out_3': 71}.\n",
      "[I 2026-02-07 12:30:32,789] Trial 9 finished with values: [0.6243, 414780.0] and parameters: {'n_layers': 3, 'conv_out_channels_0': 128, 'conv_kernel_0': 1, 'conv_stride_0': 2, 'layer_type_1': 'pool', 'layer_type_2': 'pool'}.\n",
      "[I 2026-02-07 12:33:51,689] Trial 10 finished with values: [0.8702, 26669616.0] and parameters: {'n_layers': 10, 'conv_out_channels_0': 512, 'conv_kernel_0': 3, 'conv_stride_0': 1, 'layer_type_1': 'pool', 'layer_type_2': 'pool', 'layer_type_3': 'pool', 'layer_type_4': 'linear', 'linear_out_4': 58, 'linear_out_5': 36, 'linear_out_6': 67, 'linear_out_7': 111, 'linear_out_8': 92, 'linear_out_9': 107}.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    directions=[\"maximize\",\"minimize\"],\n",
    "    study_name=\"first try for the conv model\",\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# best_trials = study.best_trials\n",
    "# print(f\"\\nNumber of Pareto-optimal trials: {len(best_trials)}\")\n",
    "\n",
    "# for t in best_trials:\n",
    "#     print(f\"  Values: accuracy={t.values[0]:.4f}, latency={t.values[1]:.4f}\")\n",
    "#     print(\"  Params:\")\n",
    "#     for k, v in t.params.items():\n",
    "#         print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42eabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.13.4 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:47] \"GET / HTTP/1.1\" 302 0\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:47] \"GET /dashboard HTTP/1.1\" 200 4145\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:48] \"GET /static/bundle.js HTTP/1.1\" 200 4140378\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:48] \"GET /favicon.ico HTTP/1.1\" 200 7670\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:48] \"GET /api/studies HTTP/1.1\" 200 314\n",
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/optuna_dashboard/_importance.py:71: ExperimentalWarning: PedAnovaImportanceEvaluator is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  study, target=target, evaluator=PedAnovaImportanceEvaluator()\n",
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/optuna/importance/_ped_anova/evaluator.py:148: UserWarning: PedAnovaImportanceEvaluator computes the importances of params to achieve low `target` values. If this is not what you want, please modify target, e.g., by multiplying the output by -1.\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:50] \"GET /api/studies/2/param_importances?evaluator=ped_anova HTTP/1.1\" 200 835\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:50] \"GET /api/studies/2?after=0 HTTP/1.1\" 200 52815\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:50] \"GET /api/meta HTTP/1.1\" 200 64\n",
      "127.0.0.1 - - [07/Feb/2026 12:34:50] \"GET /api/studies/2/param_importances?evaluator=ped_anova HTTP/1.1\" 200 835\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:00] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:10] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:20] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:30] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:41] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:35:52] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:02] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:13] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:23] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:34] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:44] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:36:55] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:05] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:16] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:26] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:37] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:48] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:37:58] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:38:09] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:38:19] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:38:29] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:38:40] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:38:50] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:01] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:11] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:22] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:32] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:43] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:39:53] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n",
      "127.0.0.1 - - [07/Feb/2026 12:40:04] \"GET /api/studies/2?after=11 HTTP/1.1\" 200 19012\n"
     ]
    }
   ],
   "source": [
    "# Start the Optuna Dashboard server on localhost:8080\n",
    "run_server(STORAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
