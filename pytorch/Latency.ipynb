{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0239fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from optuna_dashboard import run_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b989047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = Path(\"/Users/maryamhomayoon/PycharmProjects/optuna/optuna-examples/db.sqlite3\")\n",
    "DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "STORAGE = f\"sqlite:///{DB_PATH.as_posix()}\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE.type == \"mps\":\n",
    "    torch.mps.manual_seed(SEED)\n",
    "else:\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "# N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "# N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple model with only linear layer\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and #dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "    layers = []\n",
    "    in_out_features = [] \n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(f\"n_units_l{i}\", 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_out_features.append((in_features, out_features))\n",
    "        # p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        # layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    in_out_features.append((in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers) , in_out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with conv and linear while taking care of padding and while trying different strides\n",
    "def define_model(trial):\n",
    "    layers = []\n",
    "    # FashionMNIST is 28x28 grayscale images\n",
    "    in_channels = 1\n",
    "    in_height = 28\n",
    "    in_width = 28\n",
    "\n",
    "    current_features = None\n",
    "    spatial_mode = True     # a flag to control what architecture are allowed and that spatial sturctures of the connected layers makes sense\n",
    "    used_global_pool = False    # we can classify with conv -> global pooling -> classifier(log softmax)\n",
    "\n",
    "    layer_descriptions = []\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 10)\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        # First layer should be conv or if it's not conv then we need to flatten the input\n",
    "        # last layer should either be linear or we have to apply a conv with 10 output channels and then we have to apply global pooling and then classifier\n",
    "        # 10 channel conv beacause it's FashionMNIST dataset\n",
    "        # if the last global pool is not with 10 out channel then we linearly have it to 10 classes output and then go for classifier\n",
    "        if layer_idx == 0:\n",
    "            layer_type = \"conv\"\n",
    "        elif spatial_mode:\n",
    "            layer_type = trial.suggest_categorical(\n",
    "                f\"layer_type_{layer_idx}\",\n",
    "                [\"conv\", \"pool\", \"global_pool\", \"linear\"]\n",
    "            )\n",
    "        else:\n",
    "            # Once spatial structure is gone, only Linear is allowed\n",
    "            layer_type = \"linear\"\n",
    "\n",
    "        if layer_type == \"conv\":\n",
    "            out_channels = trial.suggest_categorical(\n",
    "                f\"conv_out_channels_{layer_idx}\", [16, 32, 64, 128, 256, 512]\n",
    "            )\n",
    "            kernel_size = trial.suggest_int(\n",
    "                f\"conv_kernel_{layer_idx}\", 1, 7, step=2  # odd only\n",
    "            )\n",
    "            stride = trial.suggest_categorical(\n",
    "                f\"conv_stride_{layer_idx}\", [1, 2]\n",
    "            )\n",
    "\n",
    "            # Save input shape BEFORE the layer (for latency)\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            padding = kernel_size // 2  # works with odd kernels for stride 1 and 2\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                )\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            # Output size tracking (matches your \"ceil\" style)\n",
    "            out_h = (h_in + stride - 1) // stride\n",
    "            out_w = (w_in + stride - 1) // stride\n",
    "\n",
    "            in_channels = out_channels\n",
    "            in_height = out_h\n",
    "            in_width = out_w\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"conv2d\",\n",
    "                \"out_channels\": out_channels,\n",
    "                \"kernel_size\": kernel_size,\n",
    "                \"stride\": stride,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            in_height = h_in // 2\n",
    "            in_width = w_in // 2\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"maxpool2d\",\n",
    "                \"kernel_size\": 2,\n",
    "                \"stride\": 2,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        elif layer_type == \"global_pool\":\n",
    "            c_in, h_in, w_in = in_channels, in_height, in_width\n",
    "\n",
    "            layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "            layers.append(nn.Flatten())\n",
    "\n",
    "            current_features = c_in\n",
    "\n",
    "            spatial_mode = False\n",
    "            used_global_pool = True\n",
    "\n",
    "            # After flatten, no more spatial dims\n",
    "            in_channels = None\n",
    "            in_height = None\n",
    "            in_width = None\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"global_avg_pool\",\n",
    "                \"features\": current_features,\n",
    "                \"input_shape\": (c_in, h_in, w_in),\n",
    "            })\n",
    "\n",
    "        else:  # linear\n",
    "            if spatial_mode:\n",
    "                layers.append(nn.Flatten())\n",
    "                current_features = in_channels * in_height * in_width\n",
    "                spatial_mode = False\n",
    "\n",
    "                in_channels = None\n",
    "                in_height = None\n",
    "                in_width = None\n",
    "\n",
    "            out_features = trial.suggest_int(\n",
    "                f\"linear_out_{layer_idx}\", 16, 128\n",
    "            )\n",
    "\n",
    "            layers.append(nn.Linear(current_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": out_features,\n",
    "            })\n",
    "\n",
    "            current_features = out_features\n",
    "\n",
    "    # Final classifier head\n",
    "    if used_global_pool:\n",
    "        if current_features != CLASSES:\n",
    "            layers.append(nn.Linear(current_features, CLASSES))\n",
    "            layer_descriptions.append({\n",
    "                \"type\": \"linear\",\n",
    "                \"in_features\": current_features,\n",
    "                \"out_features\": CLASSES,\n",
    "            })\n",
    "    else:\n",
    "        if spatial_mode:\n",
    "            layers.append(nn.Flatten())\n",
    "            current_features = in_channels * in_height * in_width\n",
    "\n",
    "        layers.append(nn.Linear(current_features, CLASSES))\n",
    "        layer_descriptions.append({\n",
    "            \"type\": \"linear\",\n",
    "            \"in_features\": current_features,\n",
    "            \"out_features\": CLASSES,\n",
    "        })\n",
    "\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers), layer_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_linear_cost(in_features, out_features, num_cores=1, cycles_per_mac=1):\n",
    "    macs = in_features * out_features\n",
    "    bias_adds = out_features\n",
    "    flops = 2 * macs + bias_adds\n",
    "    cycles = (macs * cycles_per_mac) / num_cores\n",
    "    return macs, flops, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_conv_cost(c_in, c_out, h_in, w_in, kernel_size, stride=1, num_cores=1, cycles_per_mac=1):\n",
    "    out_h = (h_in + stride - 1) // stride\n",
    "    out_w = (w_in + stride - 1) // stride\n",
    "\n",
    "    kernel_area = kernel_size * kernel_size\n",
    "\n",
    "    # MACs: for each output value, Cin*K*K MACs\n",
    "    macs = c_out * out_h * out_w * (c_in * kernel_area)\n",
    "\n",
    "    # FLOPs: common convention = 2 FLOPs per MAC (mul + add)\n",
    "    # plus bias adds (one add per output value)\n",
    "    bias_adds = c_out * out_h * out_w\n",
    "    flops = 2 * macs + bias_adds\n",
    "\n",
    "    # Cycles: simplest assumption (like your supervisor): 1 cycle per MAC\n",
    "    cycles = (macs * cycles_per_mac) / num_cores\n",
    "\n",
    "    return macs, flops, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c09564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_maxpool_cost(channels, input_height, input_width, kernel_size=2, stride=2, num_cores=1, cycles_per_cmp=1):\n",
    "    # Output spatial size (no padding pool)\n",
    "    out_h = (input_height - kernel_size) // stride + 1\n",
    "    out_w = (input_width  - kernel_size) // stride + 1\n",
    "\n",
    "    out_values = channels * out_h * out_w\n",
    "    comps_per_out = kernel_size * kernel_size - 1\n",
    "\n",
    "    macs = 0  # no multiply-accumulate\n",
    "    flops = out_values * comps_per_out  # not \"true FLOPs\", but op-count\n",
    "    cycles = (flops * cycles_per_cmp) / num_cores\n",
    "\n",
    "    return macs, flops, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_global_avg_pool_cost(channels, input_height, input_width, num_cores=1, cycles_per_add=1, cycles_per_div=10):\n",
    "    area = input_height * input_width\n",
    "\n",
    "    adds = channels * (area - 1)\n",
    "    divs = channels  # 1 divide per channel (or 1 multiply if you precompute reciprocal)\n",
    "\n",
    "    macs = 0\n",
    "    flops = adds + divs  # again: \"ops\" count\n",
    "    cycles = (adds * cycles_per_add + divs * cycles_per_div) / num_cores\n",
    "\n",
    "    return macs, flops, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40d273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac8d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for simple linear model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    latency = 0.0\n",
    "\n",
    "    for i, (in_f, out_f) in enumerate(out):\n",
    "        latency += estimate_linear_latency(in_f, out_f,num_cores=1, batch=BATCHSIZE)\n",
    "    trial.set_user_attr(\"latency_ms_est\", latency)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)    # since we only have linear layers we need to flatten the input first\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95487b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for conv model\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model, out = define_model(trial)\n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "    # Generate the optimizers.\n",
    "    # optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    # lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    # optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    lr = 0.001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    macs_total, flops_total, cycles_total = 0.0, 0.0, 0.0\n",
    "    macs_per_layer, flops_per_layer, cycles_per_layer = [], [], []\n",
    "\n",
    "\n",
    "    for layer in out:\n",
    "\n",
    "        if layer[\"type\"] == \"conv2d\":\n",
    "            c_in, h_in, w_in = layer[\"input_shape\"]\n",
    "            macs, flops, cycles += estimate_conv_cost(input_channels=c_in, output_channels=layer[\"out_channels\"], input_height=h_in, input_width=w_in, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"maxpool2d\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            macs, flops, cycles += estimate_maxpool_cost(channels=c, input_height=h, input_width=w, kernel_size=layer[\"kernel_size\"], stride=layer[\"stride\"])\n",
    "\n",
    "        elif layer[\"type\"] == \"global_avg_pool\":\n",
    "            c, h, w = layer[\"input_shape\"]\n",
    "            macs, flops, cycles += estimate_global_avg_pool_cost(channels=c, input_height=h, input_width=w)\n",
    "\n",
    "        elif layer[\"type\"] == \"linear\":\n",
    "            macs, flops, cycles += estimate_linear_cost(layer[\"in_features\"], layer[\"out_features\"])\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        macs_total += macs\n",
    "        flops_total += flops\n",
    "        cycles_total += cycles\n",
    "\n",
    "        macs_per_layer.append(macs)\n",
    "        flops_per_layer.append(flops)\n",
    "        cycles_per_layer.append(cycles)\n",
    "\n",
    "    # store for Optuna dashboard\n",
    "    trial.set_user_attr(\"macs_total\", macs_total)\n",
    "    trial.set_user_attr(\"flops_total\", flops_total)\n",
    "    trial.set_user_attr(\"cycles_total\", cycles_total)\n",
    "    trial.set_user_attr(\"macs_per_layer\", macs_per_layer)\n",
    "    trial.set_user_attr(\"flops_per_layer\", flops_per_layer)\n",
    "    trial.set_user_attr(\"cycles_per_layer\", cycles_per_layer)\n",
    "\n",
    "    # 2nd objective\n",
    "    latency = cycles_total\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(valid_loader.dataset)\n",
    "\n",
    "        # trial.report(accuracy, epoch)\n",
    "\n",
    "        # # Handle pruning based on the intermediate value.\n",
    "        # if trial.should_prune():\n",
    "        #     raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy, latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78634e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-07 14:53:36,170] Using an existing study with name 'first try for the conv model' instead of creating a new one.\n",
      "[I 2026-02-07 14:53:57,890] Trial 12 finished with values: [0.5639, 778748.0] and parameters: {'n_layers': 3, 'conv_out_channels_0': 16, 'conv_kernel_0': 3, 'conv_stride_0': 1, 'layer_type_1': 'pool', 'layer_type_2': 'global_pool'}.\n",
      "[I 2026-02-07 14:54:29,543] Trial 13 finished with values: [0.829, 962364.0] and parameters: {'n_layers': 7, 'conv_out_channels_0': 32, 'conv_kernel_0': 1, 'conv_stride_0': 2, 'layer_type_1': 'pool', 'layer_type_2': 'linear', 'linear_out_2': 80, 'linear_out_3': 61, 'linear_out_4': 27, 'linear_out_5': 96, 'linear_out_6': 107}.\n",
      "[I 2026-02-07 14:56:48,859] Trial 14 finished with values: [0.9054, 72253500.0] and parameters: {'n_layers': 1, 'conv_out_channels_0': 256, 'conv_kernel_0': 7, 'conv_stride_0': 1}.\n",
      "[I 2026-02-07 14:57:09,673] Trial 15 finished with values: [0.8453, 451644.0] and parameters: {'n_layers': 1, 'conv_out_channels_0': 32, 'conv_kernel_0': 1, 'conv_stride_0': 2}.\n",
      "[I 2026-02-07 14:57:38,905] Trial 16 finished with values: [0.8998, 19709358.0] and parameters: {'n_layers': 7, 'conv_out_channels_0': 32, 'conv_kernel_0': 7, 'conv_stride_0': 1, 'layer_type_1': 'pool', 'layer_type_2': 'pool', 'layer_type_3': 'conv', 'conv_out_channels_3': 128, 'conv_kernel_3': 1, 'conv_stride_3': 1, 'layer_type_4': 'conv', 'conv_out_channels_4': 32, 'conv_kernel_4': 3, 'conv_stride_4': 1, 'layer_type_5': 'pool', 'layer_type_6': 'linear', 'linear_out_6': 25}.\n",
      "[I 2026-02-07 14:58:15,733] Trial 17 finished with values: [0.8982, 31571040.0] and parameters: {'n_layers': 9, 'conv_out_channels_0': 32, 'conv_kernel_0': 5, 'conv_stride_0': 2, 'layer_type_1': 'conv', 'conv_out_channels_1': 128, 'conv_kernel_1': 5, 'conv_stride_1': 2, 'layer_type_2': 'pool', 'layer_type_3': 'linear', 'linear_out_3': 42, 'linear_out_4': 18, 'linear_out_5': 97, 'linear_out_6': 119, 'linear_out_7': 42, 'linear_out_8': 113}.\n",
      "[I 2026-02-07 14:58:41,584] Trial 18 finished with values: [0.6622, 2057894.0] and parameters: {'n_layers': 4, 'conv_out_channels_0': 16, 'conv_kernel_0': 5, 'conv_stride_0': 1, 'layer_type_1': 'global_pool', 'linear_out_2': 127, 'linear_out_3': 76}.\n",
      "[I 2026-02-07 15:02:06,422] Trial 19 finished with values: [0.8479, 65985840.0] and parameters: {'n_layers': 5, 'conv_out_channels_0': 512, 'conv_kernel_0': 1, 'conv_stride_0': 1, 'layer_type_1': 'pool', 'layer_type_2': 'pool', 'layer_type_3': 'conv', 'conv_out_channels_3': 16, 'conv_kernel_3': 5, 'conv_stride_3': 1, 'layer_type_4': 'linear', 'linear_out_4': 42}.\n",
      "[I 2026-02-07 15:02:29,633] Trial 20 finished with values: [0.7386, 4002328.0] and parameters: {'n_layers': 4, 'conv_out_channels_0': 128, 'conv_kernel_0': 5, 'conv_stride_0': 2, 'layer_type_1': 'pool', 'layer_type_2': 'global_pool', 'linear_out_3': 46}.\n",
      "[I 2026-02-07 15:02:50,844] Trial 21 finished with values: [0.3075, 179516.0] and parameters: {'n_layers': 2, 'conv_out_channels_0': 64, 'conv_kernel_0': 1, 'conv_stride_0': 2, 'layer_type_1': 'global_pool'}.\n",
      "[I 2026-02-07 15:04:08,430] Trial 22 finished with values: [0.7206, 121174022.0] and parameters: {'n_layers': 6, 'conv_out_channels_0': 256, 'conv_kernel_0': 1, 'conv_stride_0': 2, 'layer_type_1': 'conv', 'conv_out_channels_1': 16, 'conv_kernel_1': 5, 'conv_stride_1': 1, 'layer_type_2': 'global_pool', 'linear_out_3': 83, 'linear_out_4': 104, 'linear_out_5': 92}.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    directions=[\"maximize\",\"minimize\"],\n",
    "    study_name=\"first try for the conv model\",\n",
    "    storage=STORAGE,\n",
    "    load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "# pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "# complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# print(\"Study statistics: \")\n",
    "# print(\"  Number of finished trials: \", len(study.trials))\n",
    "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "# print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "# best_trials = study.best_trials\n",
    "# print(f\"\\nNumber of Pareto-optimal trials: {len(best_trials)}\")\n",
    "\n",
    "# for t in best_trials:\n",
    "#     print(f\"  Values: accuracy={t.values[0]:.4f}, latency={t.values[1]:.4f}\")\n",
    "#     print(\"  Params:\")\n",
    "#     for k, v in t.params.items():\n",
    "#         print(f\"    {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42eabae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.13.4 server starting up (using WSGIRefServer())...\n",
      "Listening on http://localhost:8080/\n",
      "Hit Ctrl-C to quit.\n",
      "\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:39] \"GET / HTTP/1.1\" 302 0\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:39] \"GET /dashboard HTTP/1.1\" 200 4145\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:39] \"GET /api/studies HTTP/1.1\" 200 314\n",
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/optuna_dashboard/_importance.py:71: ExperimentalWarning: PedAnovaImportanceEvaluator is experimental (supported from v3.6.0). The interface can change in the future.\n",
      "  study, target=target, evaluator=PedAnovaImportanceEvaluator()\n",
      "/opt/miniconda3/envs/deep/lib/python3.12/site-packages/optuna/importance/_ped_anova/evaluator.py:148: UserWarning: PedAnovaImportanceEvaluator computes the importances of params to achieve low `target` values. If this is not what you want, please modify target, e.g., by multiplying the output by -1.\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:41] \"GET /api/studies/2/param_importances?evaluator=ped_anova HTTP/1.1\" 200 837\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:41] \"GET /api/studies/2?after=0 HTTP/1.1\" 200 112772\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:41] \"GET /api/meta HTTP/1.1\" 200 64\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:41] \"GET /api/studies/2/param_importances?evaluator=ped_anova HTTP/1.1\" 200 837\n",
      "127.0.0.1 - - [07/Feb/2026 15:04:51] \"GET /api/studies/2?after=23 HTTP/1.1\" 200 25543\n"
     ]
    }
   ],
   "source": [
    "# Start the Optuna Dashboard server on localhost:8080\n",
    "run_server(STORAGE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
